{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714397d1-dd50-47c5-8dc9-8f514561af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# # Vectorstores and Embeddings\n",
    "# \n",
    "# Recall the overall workflow for \n",
    "#    Retrieval Augmented Generation (RAG):\n",
    "#\n",
    "# 1. Load documents \n",
    "# 2. Split the documents into small, \n",
    "#    semantically meaningful chunks\n",
    "# 3. Create an index for each chunk by embeddings\n",
    "#    - The index is created by embeddings which are \n",
    "#      numerical representations of text.\n",
    "#    - Text with semantically similar content has similar \n",
    "#      vectors in this numeric space.\n",
    "# 4. Store these index in a vector stores for \n",
    "#    easy retrieval when answering questions\n",
    "# 5. Search answer of a question. \n",
    "#    - Both should have similar index\n",
    "# 6. Edge Cases - Failure\n",
    "#    - 2 types of failures in similarity search\n",
    "#      + Diversity (Example)\n",
    "#      + Specifity (Example)\n",
    "#    - Solved by Advanced Retrieval\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92acb54c-264d-4de9-a2e6-a5f724ca3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "# We just discussed `Document Loading` and `Splitting`.\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5507b100-3039-4be7-9eee-bdd1262b46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "#############################################################\n",
    "# 1. Load PDF\n",
    "#\n",
    "# References of different loading:\n",
    "# - PDF\n",
    "# - Youtube\n",
    "# - URL\n",
    "# - Notion DB\n",
    "#############################################################\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\n",
    "      \"docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf\"),\n",
    "    PyPDFLoader(\n",
    "      \"docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9efee05b-7760-4600-8bac-dda8a0af765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 2. Split the content to create chunks\n",
    "#\n",
    "# References\n",
    "# - Document Splitting\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cbdb548-b1f3-4d06-a872-2f8ee59d932a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a52ef0-38a0-47ab-9868-0c22f149c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 3. Create an index for each chunk by embeddings\n",
    "# \n",
    "# Let's take our splits and embed them.\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e02ed9-cbf7-4f90-9c6c-6f37702681ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 4. Vectorstores\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f19d186f-5e54-4782-8bf2-c30161f3c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "# In[ ]:\n",
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\"\n",
    "# In[ ]:\n",
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)\n",
    "\n",
    "# In[ ]:\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4f70f8-f162-4b56-a4b6-aa7b51c9820e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9630396460189721"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "# numpy.dot(vector_a, vector_b, out = None) \n",
    "# returns the dot product of vectors a and b.\n",
    "np.dot(embedding1, embedding2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a5a958e-3733-4a47-bbd3-4e03ba298a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7702742084408517"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "np.dot(embedding1, embedding3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac89cf23-2541-4795-9a93-daf050c882fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7590147680413902"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db98daf6-efce-4bcf-970c-aa6db7f7e9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# remove old database files if any\n",
    "\n",
    "get_ipython().system('rm -rf ./docs/chroma')  \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f16f996f-2d7a-45ad-bd07-881391a7617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 5. Similarity Search\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5ef302a-fba7-4c6c-ad31-2e9092ee1e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"is there an email i can ask for help\"\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6229265b-825b-4231-9630-b4b0de731b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Library users can find help by using Ask-a-Librarian on the library website. To access the library \\ncatalog, library patrons have two options: \\n1) Using the computer in the library lobby whose home page is the catalog \\n2) Access the catalog from the library’s website \\nTo access the library’s electronic collection, library users have three options: \\n1) Using the computer in the library lobby \\n2) Access the e-library via the link on the student/faculty portal: \\na. Go to: https://my.sfbu.edu/ \\nb. Click e-Services tab, top right \\nc. Select eLibrary > ProQuest or O’Reilly \\n3) 24/7 access from anywhere is provided via EZProxy: \\na. Go to: https://elib.sfbu.edu/login \\nb. Enter your on-campus computer login information \\nc. Click on “ProQuest Digital Library” or “O’Reilly for Higher Education \\nMySFBU portal for Faculty and Students \\nFaculty members use the Canvas LMS and MySFBU faculty portal as tools to help them manage their \\nc\\nourses online, including maintaining their students’ academic and attendance records, posting and \\nupdating course syllabi, assignments, instructions, and handout materials. Teaching Assistants \\naccess the system to post homework-related information and useful learning materials for individual'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs[0].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b22108a-a8ab-4002-bd81-6ce4e5f5f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save this so we can use it later!\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d36a2c2-6512-45ba-b29f-8c64263c2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 6. Edge Case - Failure modes\n",
    "# \n",
    "# This seems great, and basic similarity \n",
    "# search will get you 80% of the way there \n",
    "# very easily. \n",
    "# \n",
    "# But there are some failure modes that can creep up. \n",
    "# \n",
    "# Here are some edge cases that can arise - we'll fix \n",
    "# them in the next class.\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "856c8b59-1f0d-489e-a261-d6fe35ada8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about departments?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a71f3b6-6f9e-4572-8333-23f0d6068301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17bdfc3d-9fe6-494b-ad0e-eff35e54acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 6.1 Edge Case 1 - Failure modes: Diversity\n",
    "# \n",
    "# Notice that we're getting duplicate chunks \n",
    "# (because of the duplicate \n",
    "# `MachineLearning-Lecture01.pdf` in the index).\n",
    "# \n",
    "# Semantic search fetches all similar documents, \n",
    "# but does not enforce diversity.\n",
    "# \n",
    "# `docs[0]` and `docs[1]` are indentical.\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58059e3c-a1b4-4e2d-bc37-c763a1b526fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 24, 'source': 'docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf'}, page_content=\"the preceding semester. \\nMany degree program classes, especially graduate courses, are conducted on weekday evenings and \\non Saturdays to allow both non-working students and working professionals to pursue their studies \\nduring after-work hours. A number of degree courses are conducted on weekdays in the daytime. \\nSince the Learning Resource Center is open during the day and on Saturday, full-time students may \\nuse weekdays’ daytime to study, conduct research, do homework, practice hands-on exercises in \\nthe labs or work on projects in the practicum labs, or engage in extracurricular activities. \\nAdministrative personnel are available during office hours to assist students, faculty, and \\nprospective applicants. \\nAddress of Instruction \\nThe address where the class sessions will be held is as follows: \\nMain Campus: 161 Mission Falls Lane, Fremont, CA 94539 \\n \\nACADEMIC POLICIES AND PROCEDURES \\nThe Provost reviews and approves University academic policies.  The Registrar administers and \\ninsures the implementation of academic policies.  The Registrar confers with the Provost on a \\nregular basis if there are any challenges to exceptions of the approved academic policies including \\ndecisions on academic standing and compliance with policies. All academic policies undergo annual \\nreview, with updates incorporated into the following year's academic catalog. \\nCredit Hour Policy \\nSFBU follows federal guidelines regarding credit hours.\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20891d6b-2843-459a-b7cf-43e80b67b8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 24, 'source': 'docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf'}, page_content=\"the preceding semester. \\nMany degree program classes, especially graduate courses, are conducted on weekday evenings and \\non Saturdays to allow both non-working students and working professionals to pursue their studies \\nduring after-work hours. A number of degree courses are conducted on weekdays in the daytime. \\nSince the Learning Resource Center is open during the day and on Saturday, full-time students may \\nuse weekdays’ daytime to study, conduct research, do homework, practice hands-on exercises in \\nthe labs or work on projects in the practicum labs, or engage in extracurricular activities. \\nAdministrative personnel are available during office hours to assist students, faculty, and \\nprospective applicants. \\nAddress of Instruction \\nThe address where the class sessions will be held is as follows: \\nMain Campus: 161 Mission Falls Lane, Fremont, CA 94539 \\n \\nACADEMIC POLICIES AND PROCEDURES \\nThe Provost reviews and approves University academic policies.  The Registrar administers and \\ninsures the implementation of academic policies.  The Registrar confers with the Provost on a \\nregular basis if there are any challenges to exceptions of the approved academic policies including \\ndecisions on academic standing and compliance with policies. All academic policies undergo annual \\nreview, with updates incorporated into the following year's academic catalog. \\nCredit Hour Policy \\nSFBU follows federal guidelines regarding credit hours.\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bc91116-3851-4bb2-8a64-640832e3343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 6.2 Edge Case 2 - Failure modes: Specifity\n",
    "#\n",
    "# We can see a new failure mode.\n",
    "# \n",
    "# The question below asks a question about \n",
    "# the third lecture, \n",
    "# but includes results from other lectures \n",
    "# as well.\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "841c2fdd-0b98-4ec7-883c-2b2ee7ddfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"what did they say about scholarship \\\n",
    "  for MSEE?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60095246-ccc3-4aee-8a32-e4cfab5dda13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search(question,k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7adfe578-0420-49cc-925a-afdc318d62af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 21, 'source': 'docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf'}\n",
      "{'page': 21, 'source': 'docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf'}\n",
      "{'page': 22, 'source': 'docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf'}\n",
      "{'page': 22, 'source': 'docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf'}\n",
      "{'page': 20, 'source': 'docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdf9c6cb-43a0-4f50-a84f-5f6227114e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required for completion. \n",
      "• Students are not eligible to receive any other SFBU academic scholarship unless \n",
      "students apply for, and are awarded, the Startup Scholars Scholarship, in which case \n",
      "the Startup Scholars Scholarship would replace this scholarship. \n",
      "• If students are unable to meet any of the terms, the tuition scholarship will be \n",
      "rescinded. \n",
      "• The university reserves the right to rescind a scholarship if it deems the decision to be \n",
      "in the best interest of the university.\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14b782d8-9352-4324-b9a9-01a662c0465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Retrieval\n",
    "# \n",
    "#  - Retrieval is the centerpiece of our retrieval \n",
    "#    augmented generation (RAG) flow. \n",
    "#    + Let's get our vectorDB from before.\n",
    "#  - Vectorstore Retrieval by Similarity Search\n",
    "#    + Could have 2 types of Edge Failures\n",
    "#      - Diversity\n",
    "#        + Solved by Maximum Marginal Relevance\n",
    "#      - Specifity \n",
    "#        + Solved by working with metadata using\n",
    "#          - Self-Query Retriever\n",
    "#          - Compression\n",
    "# - Traditional approaches which does not use Vectorstore\n",
    "#   + SVM Retrieval\n",
    "#   + TF-IDF Retrieval\n",
    "#############################################################\n",
    "\n",
    "#############################################################\n",
    "# Vectorstore retrieval\n",
    "# \n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c819cd6-c7ff-43fb-9b6a-efdcceeaf159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Similarity Search\n",
    "#############################################################\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(vectordb._collection.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33e26b82-f13c-495e-b0b4-1e9b6d25d270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='A mushroom with a large fruiting body is        the Amanita phalloides. Some varieties are        all-white.'),\n",
       " Document(metadata={}, page_content='A. phalloides, a.k.a Death Cap, is one of        the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and \\\n",
    "       imposing epigeous (aboveground) fruiting \\\n",
    "       body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is \\\n",
    "       the Amanita phalloides. Some varieties are \\\n",
    "       all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of \\\n",
    "       the most poisonous of all known mushrooms.\"\"\",\n",
    "]\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "smalldb = Chroma.from_texts(texts, embedding=embedding)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"Tell me about all-white mushrooms with \\\n",
    "       large fruiting bodies\"\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "smalldb.similarity_search(question, k=2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "smalldb.max_marginal_relevance_search(question,k=2, \n",
    "       fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "620327eb-e7e6-43a3-952c-d4de74a38795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Addressing Diversity: Maximum marginal relevance\n",
    "# \n",
    "# Last class we introduced one problem: how to enforce \n",
    "# diversity in the search results.\n",
    "#  \n",
    "# `Maximum marginal relevance` strives to achieve \n",
    "# both relevance to the query *and diversity* \n",
    "# among the results.\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e837d60-96ad-4720-a6f7-c8ad7cc100e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'such as n-grams, Hidden Markov Models, text classifiers, and recurrent neural networks. \\nPractical a'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs_ss[0].page_content[:100]\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "docs_ss[1].page_content[:100]\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9b09e3e-1b95-4889-ac8c-3910ef3ef1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program in C with UNIX/Linux system calls and other advanced topics such as the UNIX file \\nsystem, p'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################\n",
    "# Note the difference in results with `MMR`.\n",
    "#############################################################\n",
    "docs_mmr = vectordb.max_marginal_relevance_search(\n",
    "              question,k=3)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs_mmr[0].page_content[:100]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74860b00-4605-4272-ae98-3aba2c2a3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#############################################################\n",
    "# ### Addressing Specificity: working with metadata\n",
    "# \n",
    "# In last lecture, we showed that a question about \n",
    "# the third lecture can include results from other \n",
    "# lectures as well.\n",
    "# \n",
    "# To address this, many vectorstores support \n",
    "# operations on `metadata`.\n",
    "# \n",
    "# `metadata` provides context for each embedded chunk.\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fc77d5c-8985-46fb-b36e-ffbf9c9fccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 22, 'source': 'docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf'}\n",
      "{'page': 22, 'source': 'docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf'}\n",
      "{'page': 169, 'source': 'docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"what did they say about CPT \\\n",
    "            in the third trimester?\"\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\n",
    "     \"docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf\"}\n",
    ")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d6c6f92-4108-49bb-b5b6-b7141efa21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Addressing Specificity: working with metadata \n",
    "#                     using Self-Query Retriever\n",
    "# \n",
    "# But we have an interesting challenge: we often \n",
    "# want to infer the metadata from the query itself.\n",
    "# \n",
    "# To address this, we can use `SelfQueryRetriever`, \n",
    "# which uses an LLM to extract:\n",
    "#  \n",
    "# 1. The `query` string to use for vector search\n",
    "# 2. A metadata filter to pass in as well\n",
    "# \n",
    "# Most vector databases support metadata filters, \n",
    "# so this doesn't require any new databases or indexes.\n",
    "############################################################# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26ac02f6-0c6f-4c37-8ab3-75e7f75144cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "\n",
    " AttributeInfo(\n",
    "   name=\"source\",\n",
    "   description=\"The lecture the chunk is from, should \\\n",
    "      be one of \\\n",
    "      `sfbu-2024-2025-university-catalog.pdf`\",\n",
    "   type=\"string\",\n",
    "   ),\n",
    "\n",
    " AttributeInfo(\n",
    "   name=\"page\",\n",
    "   description=\"The page from the lecture\",\n",
    "   type=\"integer\",\n",
    " ),\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "question = \"what did they say about IEEE?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f725932f-5a01-4ffe-8100-7aaee6b8e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# You will receive a warning about predict_and_parse \n",
    "# being deprecated the first time you executing the \n",
    "# next line. This can be safely ignored.\n",
    "#############################################################\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata)\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e1c991a-3e18-42c8-85b3-f79548308486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Additional tricks: compression\n",
    "# \n",
    "# Another approach for improving the quality of \n",
    "# retrieved docs is compression.\n",
    "# \n",
    "# Information most relevant to a query may be \n",
    "# buried in a document with a lot of irrelevant text. \n",
    "# \n",
    "# Passing that full document through your application \n",
    "# can lead to more expensive LLM calls and poorer \n",
    "# responses.\n",
    "# \n",
    "# Contextual compression is meant to fix this. \n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a565ca3-5a16-4e0c-bc39-e60bad88441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "  print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" \n",
    "   + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6a1fd63-c6fa-41de-89c2-cfd7056e89ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "CPT Curricular Practicum\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "CPT Curricular Practicum\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "- \"Details of the qualifications are specified in the application process for the student.\"\n",
      "- \"The supervising staff is responsible for checking the students’ qualifications.\"\n",
      "- \"F-1 International students must observe additional rules required by the U.S. Immigration & Customs Enforcement on Curricular Practical Training (CPT).\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "- \"Details of the qualifications are specified in the application process for the student.\"\n",
      "- \"The supervising staff is responsible for checking the students’ qualifications.\"\n",
      "- \"F-1 International students must observe additional rules required by the U.S. Immigration & Customs Enforcement on Curricular Practical Training (CPT).\"\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Wrap our vectorstore \n",
    "#############################################################\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"what did they say about CPT?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c862202d-7673-46f5-9c20-a2d5abbf00db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Typical control cases include service and product design choices, sales forecasting, scheduling, metrics for production/inventory control, statistical quality control, and logistical constraints. MGT460L Production and Operations Management Lab (1 credit hour) Designed to be taken with MGT460, during this hands-on lab course students will learn software-based techniques to solve various time, labor, material, forecasting, capacity, take control of the conversion process from input to outputs, and costs optimizations in classic production planning and operations scenarios. Students will be expected to develop their own mathematical models, transform their models into software-based implementations and then determine the optimized best fit business solution. Students should be comfortable with or refresh themselves on solving multivariate simultaneous equations before the first-class meeting. Students should be comfortable installing software on their machines and/or using cloud-based services.\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Combining various techniques\n",
    "#############################################################\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(\n",
    "        search_type = \"mmr\")\n",
    ")\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f876f3ef-bfbd-418d-b8a3-b36860c763c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Other types of retrieval\n",
    "# \n",
    "# Traditional approaches which does not use Vectorstore\n",
    "# It's worth noting that vectordb as not the only \n",
    "#    kind of tool to retrieve documents. \n",
    "# \n",
    "# The `LangChain` retriever abstraction includes \n",
    "#    other ways to retrieve documents, such as \n",
    "#     - TF-IDF \n",
    "#     - SVM\n",
    "#############################################################\n",
    "\n",
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Load PDF\n",
    "#############################################################\n",
    "loader = PyPDFLoader(\n",
    "  \"docs/cs229_lectures/sfbu-2024-2025-university-catalog.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87ffabcd-66c0-4c2f-9d8a-e6e090c4190d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='named entity recognition, part-of-speech tagging, text classification, machine translation, \\nsentiment analysis, and language models. It also covers different models and algorithms, \\nsuch as n-grams, Hidden Markov Models, text classifiers, and recurrent neural networks. \\nPractical assignments and projects allow students to apply their knowledge to real-world   \\n \\n2024 – 2025 University Catalog  154 \\napplications and use cases such as sentiment analysis, chatbot development, and search \\nengine relevance. \\nPrerequisite: DS500 \\nDS565 Generative AI-Driven Intelligent Apps Development (3 credit hours) \\nIn the fast-changing world of technology, the demand for intelligent applications powered \\nby AI and ML is rapidly increasing. This course aims to provide students with the necessary \\nexpertise to develop cutting-edge applications and harness the potential of generative AI \\ntechnology. Intelligent apps using generative AI technology stand apart from traditional \\napps by offering enhanced creativity, adaptive learning, personalized user experiences, \\nautomation and decision-making capabilities, as well as human-like conversational abilities. \\nThis course equips students with the skills to develop innovative apps that leverage the \\npower of AI. Topics include an introduction to generative AI, deep learning, and machine \\nlearning techniques, implementing generative models for various domains, ethical')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################\n",
    "# Split\n",
    "#############################################################\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Retrieve\n",
    "#############################################################\n",
    "\n",
    "#############################################################\n",
    "# SVM Retriever\n",
    "#############################################################\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "\n",
    "#############################################################\n",
    "# TFIDF Retriever\n",
    "#############################################################\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Retrieve with SVM Retriever\n",
    "#############################################################\n",
    "question = \"What are major topics for genAI class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d2843a8-43d2-4942-acb0-157cb940df40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='o NC = (No credit) The student did not pass a challenge examination. Prior to May \\n1998 the grade NC might also be issued to a student taking an ESL course. \\no U = (Unauthorized withdraw) The student did not withdraw from the course \\nbut failed to meet attendance and course requirements. “U” grade equals “F” \\ngrade. \\no * = Co urse  has been repeated. \\nGrade Point Average (GPA and CGPA) \\nThe grade point average (GPA) is based on courses in which letter grades are earned. \\nInstructors may add plus (+) or minus (-) options to letter grades in order to refine \\nevaluation procedures. GPA may be calculated either based on semester, or cumulatively \\n(CGPA). CGPA is calculated based on all courses and grades earned to meet a degree \\nprogram’s graduation requirements. To compute the GPA or CGPA, divide the total \\nnumber of grade points by the total number of credit hours attempted in courses \\nreceiving letter grades. Use the following table for grade point assignments: \\nGrade Points \\nA+ 4.0 \\nA 4.0 \\nA- 3.7 \\nB+ 3.3 \\nB 3.0 \\nB- 2.7   \\n \\n2024 – 2025 University Catalog  29 \\nC+ 2.3 \\nC 2.0 \\nC- 1.7 \\nD+ 1.3 \\nD 1.0 \\nD- 0.7 \\nF 0.0 \\nU 0.0 \\nAll other grading symbols receive no grade points, and credit hours for those courses are \\nexcluded from computation for GPA or CGPA. \\nGraduate level programs require a CGPA of 3.0 or higher to meet graduation \\nrequirements. Undergraduate degree programs require a CGPA of 2.0 or higher to meet \\ngraduation requirements \\nPassing Grades \\nUndergraduate Programs')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Retrieve with TFIDF Retriever\n",
    "#############################################################\n",
    "question = \"what did they say about graduation?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
