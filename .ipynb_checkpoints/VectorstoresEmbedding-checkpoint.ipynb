{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd79bc-87f9-4682-9cb3-61b44e8303dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/JTasnim/LangChainChat/blob/main/VectorstoresEmbedding.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714397d1-dd50-47c5-8dc9-8f514561af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# # Vectorstores and Embeddings\n",
    "# \n",
    "# Recall the overall workflow for \n",
    "#    Retrieval Augmented Generation (RAG):\n",
    "#\n",
    "# 1. Load documents \n",
    "# 2. Split the documents into small, \n",
    "#    semantically meaningful chunks\n",
    "# 3. Create an index for each chunk by embeddings\n",
    "#    - The index is created by embeddings which are \n",
    "#      numerical representations of text.\n",
    "#    - Text with semantically similar content has similar \n",
    "#      vectors in this numeric space.\n",
    "# 4. Store these index in a vector stores for \n",
    "#    easy retrieval when answering questions\n",
    "# 5. Search answer of a question. \n",
    "#    - Both should have similar index\n",
    "# 6. Edge Cases - Failure\n",
    "#    - 2 types of failures in similarity search\n",
    "#      + Diversity (Example)\n",
    "#      + Specifity (Example)\n",
    "#    - Solved by Advanced Retrieval\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92acb54c-264d-4de9-a2e6-a5f724ca3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "# We just discussed `Document Loading` and `Splitting`.\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5507b100-3039-4be7-9eee-bdd1262b46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "#############################################################\n",
    "# 1. Load PDF\n",
    "#\n",
    "# References of different loading:\n",
    "# - PDF\n",
    "# - Youtube\n",
    "# - URL\n",
    "# - Notion DB\n",
    "#############################################################\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\n",
    "      \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\n",
    "      \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9efee05b-7760-4600-8bac-dda8a0af765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 2. Split the content to create chunks\n",
    "#\n",
    "# References\n",
    "# - Document Splitting\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cbdb548-b1f3-4d06-a872-2f8ee59d932a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a52ef0-38a0-47ab-9868-0c22f149c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 3. Create an index for each chunk by embeddings\n",
    "# \n",
    "# Let's take our splits and embed them.\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f19d186f-5e54-4782-8bf2-c30161f3c2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7590147680413902"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "# In[ ]:\n",
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\"\n",
    "# In[ ]:\n",
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)\n",
    "\n",
    "# In[ ]:\n",
    "import numpy as np\n",
    "# In[ ]:\n",
    "# numpy.dot(vector_a, vector_b, out = None) \n",
    "# returns the dot product of vectors a and b.\n",
    "np.dot(embedding1, embedding2)\n",
    "# In[ ]:\n",
    "np.dot(embedding1, embedding3)\n",
    "# In[ ]:\n",
    "np.dot(embedding2, embedding3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e02ed9-cbf7-4f90-9c6c-6f37702681ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 4. Vectorstores\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db98daf6-efce-4bcf-970c-aa6db7f7e9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# remove old database files if any\n",
    "\n",
    "get_ipython().system('rm -rf ./docs/chroma')  \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f16f996f-2d7a-45ad-bd07-881391a7617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 5. Similarity Search\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d5ef302a-fba7-4c6c-ad31-2e9092ee1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"is there an email i can ask for help\"\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "len(docs)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs[0].page_content\n",
    "\n",
    "\n",
    "# Let's save this so we can use it later!\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d36a2c2-6512-45ba-b29f-8c64263c2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 6. Edge Case - Failure modes\n",
    "# \n",
    "# This seems great, and basic similarity \n",
    "# search will get you 80% of the way there \n",
    "# very easily. \n",
    "# \n",
    "# But there are some failure modes that can creep up. \n",
    "# \n",
    "# Here are some edge cases that can arise - we'll fix \n",
    "# them in the next class.\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "856c8b59-1f0d-489e-a261-d6fe35ada8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17bdfc3d-9fe6-494b-ad0e-eff35e54acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 6.1 Edge Case 1 - Failure modes: Diversity\n",
    "# \n",
    "# Notice that we're getting duplicate chunks \n",
    "# (because of the duplicate \n",
    "# `MachineLearning-Lecture01.pdf` in the index).\n",
    "# \n",
    "# Semantic search fetches all similar documents, \n",
    "# but does not enforce diversity.\n",
    "# \n",
    "# `docs[0]` and `docs[1]` are indentical.\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58059e3c-a1b4-4e2d-bc37-c763a1b526fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}, page_content='those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it\\'s free, and for the purposes of this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine learning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, like, ten years ago came \\ninto his office and he said, \"Oh, professor, professor, thank you so much for your')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs[0]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bc91116-3851-4bb2-8a64-640832e3343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 6.2 Edge Case 2 - Failure modes: Specifity\n",
    "#\n",
    "# We can see a new failure mode.\n",
    "# \n",
    "# The question below asks a question about \n",
    "# the third lecture, \n",
    "# but includes results from other lectures \n",
    "# as well.\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "841c2fdd-0b98-4ec7-883c-2b2ee7ddfc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 13, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"what did they say about regression \\\n",
    "  in the third lecture?\"\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search(question,k=5)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdf9c6cb-43a0-4f50-a84f-5f6227114e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he says it in sort of a really touching, sincere way, and then he has this — you can see it \n",
      "in his eyes — he has this deep appreciation of the truth and beauty in the universe as \n",
      "revealed to him by the math he does.  \n",
      "In this class, I'm not gonna do any truth and beauty. In this class, I'm gonna talk about \n",
      "learning theory to try to convey to you an understanding of how and why learning \n",
      "algorithms work so that we can apply these learning algorithms as effectively as possible.  \n",
      "So, for example, it turns out you can prove surprisingly deep theorems on when you can \n",
      "guarantee that a learning algorithm will work, all right? So think about a learning\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14b782d8-9352-4324-b9a9-01a662c0465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Retrieval\n",
    "# \n",
    "#  - Retrieval is the centerpiece of our retrieval \n",
    "#    augmented generation (RAG) flow. \n",
    "#    + Let's get our vectorDB from before.\n",
    "#  - Vectorstore Retrieval by Similarity Search\n",
    "#    + Could have 2 types of Edge Failures\n",
    "#      - Diversity\n",
    "#        + Solved by Maximum Marginal Relevance\n",
    "#      - Specifity \n",
    "#        + Solved by working with metadata using\n",
    "#          - Self-Query Retriever\n",
    "#          - Compression\n",
    "# - Traditional approaches which does not use Vectorstore\n",
    "#   + SVM Retrieval\n",
    "#   + TF-IDF Retrieval\n",
    "#############################################################\n",
    "\n",
    "#############################################################\n",
    "# Vectorstore retrieval\n",
    "# \n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c819cd6-c7ff-43fb-9b6a-efdcceeaf159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Similarity Search\n",
    "#############################################################\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(vectordb._collection.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33e26b82-f13c-495e-b0b4-1e9b6d25d270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='A mushroom with a large fruiting body is        the Amanita phalloides. Some varieties are        all-white.'),\n",
       " Document(metadata={}, page_content='A. phalloides, a.k.a Death Cap, is one of        the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and \\\n",
    "       imposing epigeous (aboveground) fruiting \\\n",
    "       body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is \\\n",
    "       the Amanita phalloides. Some varieties are \\\n",
    "       all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of \\\n",
    "       the most poisonous of all known mushrooms.\"\"\",\n",
    "]\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "smalldb = Chroma.from_texts(texts, embedding=embedding)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"Tell me about all-white mushrooms with \\\n",
    "       large fruiting bodies\"\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "smalldb.similarity_search(question, k=2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "smalldb.max_marginal_relevance_search(question,k=2, \n",
    "       fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "620327eb-e7e6-43a3-952c-d4de74a38795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Addressing Diversity: Maximum marginal relevance\n",
    "# \n",
    "# Last class we introduced one problem: how to enforce \n",
    "# diversity in the search results.\n",
    "#  \n",
    "# `Maximum marginal relevance` strives to achieve \n",
    "# both relevance to the query *and diversity* \n",
    "# among the results.\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e837d60-96ad-4720-a6f7-c8ad7cc100e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people c'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs_ss[0].page_content[:100]\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "docs_ss[1].page_content[:100]\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9b09e3e-1b95-4889-ac8c-3910ef3ef1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'into his office and he said, \"Oh, professor, professor, thank you so much for your \\nmachine learning'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################\n",
    "# Note the difference in results with `MMR`.\n",
    "#############################################################\n",
    "docs_mmr = vectordb.max_marginal_relevance_search(\n",
    "              question,k=3)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs_mmr[0].page_content[:100]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74860b00-4605-4272-ae98-3aba2c2a3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#############################################################\n",
    "# ### Addressing Specificity: working with metadata\n",
    "# \n",
    "# In last lecture, we showed that a question about \n",
    "# the third lecture can include results from other \n",
    "# lectures as well.\n",
    "# \n",
    "# To address this, many vectorstores support \n",
    "# operations on `metadata`.\n",
    "# \n",
    "# `metadata` provides context for each embedded chunk.\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fc77d5c-8985-46fb-b36e-ffbf9c9fccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"what did they say about regression \\\n",
    "            in the third lecture?\"\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\n",
    "     \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"}\n",
    ")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d6c6f92-4108-49bb-b5b6-b7141efa21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Addressing Specificity: working with metadata \n",
    "#                     using Self-Query Retriever\n",
    "# \n",
    "# But we have an interesting challenge: we often \n",
    "# want to infer the metadata from the query itself.\n",
    "# \n",
    "# To address this, we can use `SelfQueryRetriever`, \n",
    "# which uses an LLM to extract:\n",
    "#  \n",
    "# 1. The `query` string to use for vector search\n",
    "# 2. A metadata filter to pass in as well\n",
    "# \n",
    "# Most vector databases support metadata filters, \n",
    "# so this doesn't require any new databases or indexes.\n",
    "############################################################# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26ac02f6-0c6f-4c37-8ab3-75e7f75144cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "\n",
    " AttributeInfo(\n",
    "   name=\"source\",\n",
    "   description=\"The lecture the chunk is from, should \\\n",
    "      be one of \\\n",
    "      `docs/cs229_lectures/MachineLearning-Lecture01.pdf`\",\n",
    "   type=\"string\",\n",
    "   ),\n",
    "\n",
    " AttributeInfo(\n",
    "   name=\"page\",\n",
    "   description=\"The page from the lecture\",\n",
    "   type=\"integer\",\n",
    " ),\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")\n",
    "question = \"what did they say about regression in the third lecture?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f725932f-5a01-4ffe-8100-7aaee6b8e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# You will receive a warning about predict_and_parse \n",
    "# being deprecated the first time you executing the \n",
    "# next line. This can be safely ignored.\n",
    "#############################################################\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata)\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c991a-3e18-42c8-85b3-f79548308486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Additional tricks: compression\n",
    "# \n",
    "# Another approach for improving the quality of \n",
    "# retrieved docs is compression.\n",
    "# \n",
    "# Information most relevant to a query may be \n",
    "# buried in a document with a lot of irrelevant text. \n",
    "# \n",
    "# Passing that full document through your application \n",
    "# can lead to more expensive LLM calls and poorer \n",
    "# responses.\n",
    "# \n",
    "# Contextual compression is meant to fix this. \n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a565ca3-5a16-4e0c-bc39-e60bad88441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "  print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" \n",
    "   + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6a1fd63-c6fa-41de-89c2-cfd7056e89ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "- those homeworks will be done in either MATLAB or in Octave\n",
      "- I know some people call it a free version of MATLAB\n",
      "- MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data\n",
      "- it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms\n",
      "- there's also a software package called Octave that you can download for free off the Internet\n",
      "- it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about everything\n",
      "- once a colleague of mine at a different university, not at Stanford, actually teaches another machine learning course\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- those homeworks will be done in either MATLAB or in Octave\n",
      "- I know some people call it a free version of MATLAB\n",
      "- MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data\n",
      "- it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms\n",
      "- there's also a software package called Octave that you can download for free off the Internet\n",
      "- it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about everything\n",
      "- once a colleague of mine at a different university, not at Stanford, actually teaches another machine learning course\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Wrap our vectorstore \n",
    "#############################################################\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c862202d-7673-46f5-9c20-a2d5abbf00db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "- those homeworks will be done in either MATLAB or in Octave\n",
      "- I know some people call it a free version of MATLAB\n",
      "- MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data\n",
      "- it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms\n",
      "- there's also a software package called Octave that you can download for free off the Internet\n",
      "- it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about everything\n",
      "- once a colleague of mine at a different university, not at Stanford, actually teaches another machine learning course\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "- \"one very successful approach is to use a learning algorithm and have a computer learn by itself how to, say, recognize your handwriting.\"\n",
      "- \"Learning algorithms has also made I guess significant inroads in what's sometimes called database mining.\"\n",
      "- \"applying learning algorithms to them can turn raw medical records into what I might loosely call medical knowledge\"\n",
      "- \"medical knowledge that's derived by applying learning algorithms to the sorts of medical records that hospitals have just been building over the last 15, 20 years in an electronic format.\"\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Combining various techniques\n",
    "#############################################################\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(\n",
    "        search_type = \"mmr\")\n",
    ")\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f876f3ef-bfbd-418d-b8a3-b36860c763c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content=\"yourselves. You can also come and talk to me or the TAs if you want to brainstorm ideas \\nwith us.  \\nOkay. So one more organizational question. I'm curious, how many of you know \\nMATLAB? Wow, cool, quite a lot. Okay. So as part of the — act ually how many of you \\nknow Octave or have used Octave? Oh, okay, much smaller number.  \\nSo as part of this class, especially in the homeworks, we'll ask you to implement a few \\nprograms, a few machine learning algorithms as part of the homeworks. And most of  those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn't.  \\nSo I guess for those of you that haven't seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon't have a MATLAB license, for the purposes of this class, there's also — [inaudible] \\nwrite that down [inaudible] MATLAB — there' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it's free, and for the purposes of this class, it will work for just about \\neverything.\")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################\n",
    "# Other types of retrieval\n",
    "# \n",
    "# Traditional approaches which does not use Vectorstore\n",
    "# It's worth noting that vectordb as not the only \n",
    "#    kind of tool to retrieve documents. \n",
    "# \n",
    "# The `LangChain` retriever abstraction includes \n",
    "#    other ways to retrieve documents, such as \n",
    "#     - TF-IDF \n",
    "#     - SVM\n",
    "#############################################################\n",
    "\n",
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Load PDF\n",
    "#############################################################\n",
    "loader = PyPDFLoader(\n",
    "  \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "#############################################################\n",
    "# Split\n",
    "#############################################################\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Retrieve\n",
    "#############################################################\n",
    "\n",
    "#############################################################\n",
    "# SVM Retriever\n",
    "#############################################################\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "\n",
    "#############################################################\n",
    "# TFIDF Retriever\n",
    "#############################################################\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Retrieve with SVM Retriever\n",
    "#############################################################\n",
    "question = \"What are major topics for this class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Retrieve with TFIDF Retriever\n",
    "#############################################################\n",
    "question = \"what did they say about matlab?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ffabcd-66c0-4c2f-9d8a-e6e090c4190d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
